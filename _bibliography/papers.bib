---
---

@article{sun2024knowledge,
abbr={arxiv},
  title={Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback},
  author={Sun, Jingwei and Du, Zhixu and Chen, Yiran},
  journal={arXiv preprint arXiv:2405.19686},
  year={2024},
  pdf={https://arxiv.org/pdf/2405.19686},
  selected={true}
}


@article{sun2023fedbpt,
abbr={ICML},
bibtex_show={true},
  title={FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models},
  author={Sun, Jingwei and Xu, Ziyue and Yin, Hongxu and Yang, Dong and Xu, Daguang and Liu, Yudong and Du, Zhixu and Chen, Yiran and Roth, Holger R},
  journal={Proceedings of the 41th International Conference on Machine Learning},
  year={2024},
  award={Best Paper Award in Federated Learning on the Edge, 2024 AAAI Spring Series Symposium},
  pdf={https://arxiv.org/pdf/2310.01467},
  website={https://jingwei-sun.com/FedBPT/},
  selected={true}
}



@article{du2023sida,
abbr={MLSys},
bibtex_show={true},
  title={SiDA: Sparsity-Inspired Data-Aware Serving for Efficient and Scalable Large Mixture-of-Experts Models},
  author={Du, Zhixu and Li, Shiyu and Wu, Yuhao and Jiang, Xiangyu and Sun, Jingwei and Zheng, Qilin and Wu, Yongkai and Li, Ang and Li, Hai and Chen, Yiran and others},
  journal={MLSys2024},
  year={2024}
}

@article{duan2024privascissors,
abbr={NeurIPS},
  title={Reimagining Mutual Information for Enhanced Defense against Data Leakage in Collaborative Inference},
  author={Duan*, Lin and Sun*, Jingwei and Chen, Yiran and Gorlatova, Maria},
  journal={NeurIPS},
  year={2024},
  pdf={https://openreview.net/pdf?id=tdZLKY9usl},
  selected={true}
}

@article{sun2023robust,
abbr={arxiv},
  title={Robust and IP-Protecting Vertical Federated Learning against Unexpected Quitting of Parties},
  author={Sun, Jingwei and Du, Zhixu and Dai, Anna and Baghersalimi, Saleh and Amirshahi, Alireza and Atienza, David and Chen, Yiran},
  journal={arXiv preprint arXiv:2303.18178},
  year={2023},
  pdf={https://arxiv.org/pdf/2303.18178.pdf}
}

@article{sun2023communication,
abbr={ICCV},
bibtex_show={true},
  title={Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples},
  author={Sun, Jingwei and Xu, Ziyue and Yang, Dong and Nath, Vishwesh and Li, Wenqi and Zhao, Can and Xu, Daguang and Chen, Yiran and Roth, Holger R},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023},
  pdf={https://arxiv.org/pdf/2303.16270.pdf},
  selected={true}
}



@article{sun2022fedsea,
abbr={SenSys},
bibtex_show={true},
  title={FedSEA: A Semi-Asynchronous Federated Learning Framework for Extremely Heterogeneous Devices},
  author={Sun, Jingwei and Li, Ang and Duan, Lin and Alam, Samiul and Deng, Xuliang and Guo, Xin and Wang, Haiming and Gorlatova, Maria and Zhang, Mi and Li, Hai and others},
  abstract = {Federated learning (FL) has attracted increasing attention as a promising technique to drive a vast number of edge devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of a FL system in practice due to the heterogeneous computation resources on different devices. To improve the efficiency of FL systems in the real world, asynchronous FL (AFL) and semi-asynchronous FL (SAFL) methods are proposed such that the server does not need to wait for stragglers. However, existing AFL and SAFL systems suffer from poor accuracy and low efficiency in realistic settings where the data is non-IID distributed across devices and the on-device resources are extremely heterogeneous. In this work, we propose FedSEA - a semi-asynchronous FL framework for extremely heterogeneous devices. We theoretically disclose that the unbalanced aggregation frequency is a root cause of accuracy drop in SAFL. Based on this analysis, we design a training configuration scheduler to balance the aggregation frequency of devices such that the accuracy can be improved. To improve the efficiency of the system in realistic settings where the devices have dynamic on-device resource availability, we design a scheduler that can efficiently predict the arriving time of local updates from devices and adjust the synchronization time point according to the devices' predicted arriving time. We also consider the extremely heterogeneous settings where there exist extremely lagging devices that take hundreds of times as long as the training time of the other devices. In the real world, there might be even some extreme stragglers which are not capable of training the global model. To enable these devices to join in training without impairing the systematic efficiency, Fed-SEA enables these extreme stragglers to conduct local training on much smaller models. Our experiments show that compared with status quo approaches, FedSEA improves the inference accuracy by 44.34% and reduces the systematic time cost and local training time cost by 87.02X and 792.9X. FedSEA also reduces the energy consumption of the devices with extremely limited resources by 752.9X.},
  booktitle={Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
  pdf={https://www.researchgate.net/profile/Mi-Zhang-13/publication/366702532_FedSEA_A_Semi-Asynchronous_Federated_Learning_Framework_for_Extremely_Heterogeneous_Devices/links/63af5e0da03100368a3dd71d/FedSEA-A-Semi-Asynchronous-Federated-Learning-Framework-for-Extremely-Heterogeneous-Devices.pdf},
  html={https://doi.org/10.1145/3560905.3568538},
  year={2022},
  selected={true}
}

@inproceedings{li2021lotteryfl,
abbr={SEC},
bibtex_show={true},
  title={LotteryFL: empower edge intelligence with personalized and communication-efficient federated learning},
  author={Li, Ang and Sun, Jingwei and Wang, Binghui and Duan, Lin and Li, Sicheng and Chen, Yiran and Li, Hai},
  booktitle={2021 IEEE/ACM Symposium on Edge Computing (SEC)},
  pages={68--79},
  year={2021},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/document/9708944},
  arxiv={https://arxiv.org/pdf/2008.03371.pdf},
  code={https://github.com/charleslipku/LotteryFL}
}

@inproceedings{sun2021soteria,
abbr={CVPR},
bibtex_show={true},
  title={Soteria: Provable defense against privacy leakage in federated learning from representation perspective},
  author={Sun, Jingwei and Li, Ang and Wang, Binghui and Yang, Huanrui and Li, Hai and Chen, Yiran},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9311--9319},
  year={2021},
  code={https://github.com/jeremy313/Soteria},
  pdf={https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.pdf},
  selected={true}
}

@inproceedings{li2021hermes,
abbr={MobiCom},
bibtex_show={true},
  title={Hermes: an efficient federated learning framework for heterogeneous mobile clients},
  author={Li, Ang and Sun, Jingwei and Li, Pengcheng and Pu, Yu and Li, Hai and Chen, Yiran},
  booktitle={Proceedings of the 27th Annual International Conference on Mobile Computing and Networking},
  pages={420--437},
  year={2021},
  pdf={hermes.pdf},
  selected={true}
}

@article{sun2021fl,
abbr={NeurIPS},
bibtex_show={true},
  title={Fl-wbc: Enhancing robustness against model poisoning attacks in federated learning from a client perspective},
  author={Sun, Jingwei and Li, Ang and DiValentin, Louis and Hassanzadeh, Amin and Chen, Yiran and Li, Hai},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12613--12624},
  year={2021},
  pdf={https://proceedings.neurips.cc/paper/2021/file/692baebec3bb4b53d7ebc3b9fabac31b-Paper.pdf},
  code={https://github.com/jeremy313/FL-WBC},
  selected={true}
}

@inproceedings{li2021fedmask,
abbr={SenSys},
bibtex_show={true},
  title={Fedmask: Joint computation and communication-efficient personalized federated learning via heterogeneous masking},
  author={Li, Ang and Sun, Jingwei and Zeng, Xiao and Zhang, Mi and Li, Hai and Chen, Yiran},
  booktitle={Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
  pages={42--55},
  year={2021},
  pdf={https://par.nsf.gov/servlets/purl/10301269},
  html={https://dl.acm.org/doi/abs/10.1145/3485730.3485929},
  selected={true}
}


@article{zhang2022fed,
abbr={ICML},
  title={Fed-CBS: A Heterogeneity-Aware Client Sampling Mechanism for Federated Learning via Class-Imbalance Reduction},
  author={Zhang, Jianyi and Li, Ang and Tang, Minxue and Sun, Jingwei and Chen, Xiang and Zhang, Fan and Chen, Changyou and Chen, Yiran and Li, Hai},
  journal={arXiv preprint arXiv:2209.15245},
  year={2023},
  pdf={https://arxiv.org/pdf/2209.15245.pdf}
}

@inproceedings{du2022rethinking,
abbr={DistributedML},
  title={Rethinking normalization methods in federated learning},
  author={Du*, Zhixu and Sun*, Jingwei and Li, Ang and Chen, Pin-Yu and Zhang, Jianyi and Li, Hai Li and Chen, Yiran},
  booktitle={Proceedings of the 3rd International Workshop on Distributed Machine Learning},
  pages={16--22},
  year={2022},
  pdf={https://arxiv.org/pdf/2210.03277.pdf}
}

@inproceedings{zhang2022next,
abbr={CIC},
bibtex_show={true},
  title={Next Generation Federated Learning for Edge Devices: An Overview},
  author={Zhang, Jianyi and Du, Zhixu and Sun, Jingwei and Li, Ang and Tang, Minxue and Wu, Yuhao and Gao, Zhihui and Kuo, Martin and Li, Hai-Helen and Chen, Yiran},
  booktitle={2022 IEEE 8th International Conference on Collaboration and Internet Computing (CIC)},
  pages={10--15},
  year={2022},
  organization={IEEE},
  IEEE={https://ieeexplore.ieee.org/abstract/document/10061731}
}
